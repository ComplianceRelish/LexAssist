
# Supabase Configuration
SUPABASE_URL=your-supabase-url-here
SUPABASE_ANON_KEY=your-supabase-anon-key-here

# Vercel Configuration
VERCEL_PROJECT_ID=your-vercel-project-id-here
VERCEL_TEAM_ID=your-vercel-team-id-here
VERCEL_TOKEN=your-vercel-token-here

# Google Cloud Run Configuration
VITE_BACKEND_URL=https://lexassist-438720587503.europe-west1.run.app
CLOUD_RUN=true
PORT=8000
BACKEND_URL=https://lexassist-438720587503.europe-west1.run.app
GOOGLE_CLOUD_API_KEY=your-google-cloud-api-key-here
CORS_ALLOWED_ORIGINS=https://lex-assist.vercel.app,http://localhost:3000,http://localhost:5173,https://lexassist-438720587503.europe-west1.run.app

# GitHub Configuration
GITHUB_URL=https://github.com/ComplianceRelish/LexAssist.git
GITHUB_TOKEN=your-github-token-here

PINECONE_API_KEY=your-pinecone-api-key
PINECONE_ENVIRONMENT=aped-4627-b74a
PINECONE_INDEX_NAME=lexassist
ASSEMBLY_AI_API_KEY=your-assemble-api-key
NEO4J_USERNAME=neo4j

NEO4J_PASSWORD=your-neo4j-password
OPENAI_API_KEY=your-openai-api-key
INDIAN_KANOON_API_KEY=your-indian-kanoon-api-key


# Supabase Configuration
SUPABASE_URL=your-supabase-url-here
SUPABASE_ANON_PUBLIC_KEY=your-supabase-anon-public-key-here
SUPABASE_JWT_SECRET=your-supabase-jwt-secret-here
SUPABASE_SERVICE_ROLE_KEY=your-supabase-service-role-key-here

# Redis Configuration
REDIS_URL=redis://localhost:6379
REDIS_API_ACCOUNT_KEY=your-redis-api-account-key
REDIS_API_USER_KEY=your-redis-api-user-key

# InLegalBERT Configuration
INLEGALBERT_MODEL_PATH=law-ai/InLegalBERT
HUGGINGFACE_TOKEN=your-huggingface-token
ENABLE_INLEGALBERT=true
INLEGALBERT_CACHE_DIR=/path/to/model/cache

InLegalBERT Environment Variables in Cloud Run:
# InLegalBERT Configuration
HF_HOME=/app/huggingface                       # Custom cache directory
TRANSFORMERS_CACHE=/app/huggingface/models     # Model storage location
INLEGALBERT_MODEL_PATH=law-ai/InLegalBERT      # Model identifier

# Inference Settings
INLEGALBERT_MAX_LENGTH=512                     # Maximum sequence length
INLEGALBERT_BATCH_SIZE=4                       # Batch size for inference
INLEGALBERT_USE_GPU=0                          # Set to 1 if GPU available

# Optional: For fine-tuning
INLEGALBERT_LEARNING_RATE=2e-5
INLEGALBERT_EPOCHS=3
INLEGALBERT_TRAIN_BATCH_SIZE=8

HUGGINGFACE_TOKEN=you-huggingface-token


VITE_API_TIMEOUT=30000
VITE_ENABLE_API_LOGS=true
VITE_MAX_RETRY_ATTEMPTS=3
VITE_RETRY_DELAY=1000
VITE_APP_VERSION=1.0.0

# Add to your .env file
RAGFLOW_API_URL=http://localhost:9380
RAGFLOW_API_KEY=your_ragflow_api_key

# Enhanced DeepSeek settings
DEEPSEEK_API_KEY=your-deepseek-api-key
DEEPSEEK_BASE_URL=https://api.deepseek.com
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_ENABLE_STREAMING=true

# Multi-modal support
DEEPSEEK_VISION_MODEL=deepseek-vl-7b-chat
ENABLE_MULTIMODAL=true

OPENAI_API_KEY=you_openai-api-key_here


SENDGRID_API_KEY=your_sendgrid_api_key_here
SENDGRID_ACCOUNT_ID=you_sendgrid_account_id_here

TWILIO_API_KEY=your_twilio_api_key_here
TWILIO_AUTH_TOKEN=your_twilio_auth_token_here
VERIFY_SERVICE_SID=your_verify_service_sid_here