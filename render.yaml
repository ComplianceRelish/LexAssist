services:
  - type: web
    name: lexassist-backend
    runtime: python
    plan: pro  # Upgraded for more memory
    rootDir: legal_app/backend
    buildCommand: |
      python -c 'import nltk; nltk.download("punkt"); nltk.download("stopwords")'
    startCommand: "gunicorn main:app -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:$PORT --workers 1 --max-requests 100 --max-requests-jitter 10"
    disk:
      name: huggingface-cache
      mountPath: /app/cache
      sizeGB: 3
    envVars:
      # HuggingFace and model caching - use /tmp for better permissions
      - key: TRANSFORMERS_CACHE
        value: /tmp/huggingface
      - key: HF_HOME
        value: /tmp/huggingface
      - key: HF_DATASETS_CACHE
        value: /tmp/huggingface/datasets
      # Memory optimization
      - key: PYTORCH_CUDA_ALLOC_CONF
        value: max_split_size_mb:32,garbage_collection_threshold:0.6
      - key: MALLOC_TRIM_THRESHOLD_
        value: 65536
      - key: USE_HALF_PRECISION
        value: "true"
      - key: TOKENIZERS_PARALLELISM
        value: "false"
      # Load smaller models when possible
      - key: WHISPER_MODEL_SIZE
        value: "tiny"
      - key: INLEGALBERT_MODEL_PATH
        value: law-ai/InLegalBERT
      - key: INLEGALBERT_MAX_LENGTH
        value: "256"
      # Application settings
      - key: PORT
        value: 10000
      - key: SUPABASE_URL
        value: https://meuyiktpkeomskqornnu.supabase.co
      - key: SUPABASE_ANON_KEY
        value: eyJhbGciOiJIUzI1NiIsImtpZCI6Ilp1eDFLZ3VsUkx6cU5JM3QiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL21ldXlpa3Rwa2VvbXNrcW9ybm51LnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzQ5MzY0NDExLCJpYXQiOjE3NDkzNjA4MTEsImVtYWlsIjoicmVsaXNoZm9vZHNAcHJvdG9uLm1lIiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCJdfSwidXNlcl9tZXRhZGF0YSI6eyJjb3VudHJ5IjoiSU4iLCJjb3VudHJ5X2NvZGUiOiIrOTEiLCJlbWFpbCI6InJlbGlzaGZvb2RzQHByb3Rvbi5tZSIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJmdWxsX25hbWUiOiJNb3R0eSBQaGlsaXAiLCJwaG9uZSI6Iis5MTk0NDYwMTIzMjQiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInN1YiI6ImRiNTliYWVjLWVjNjEtNGI5OC1iZGI4LTgyMWJmMzMyZWM4YiIsInVzZXJfdHlwZSI6ImNsaWVudCJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6InBhc3N3b3JkIiwidGltZXN0YW1wIjoxNzQ5MzYwODExfV0sInNlc3Npb25faWQiOiI2MTQ2MGRhMC1jYzdhLTQ5NzUtOTg4Zi02NjYxMTY1M2RhNTYiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ
      - key: SUPABASE_JWT_SECRET
        sync: false
      - key: SUPABASE_SERVICE_ROLE_KEY
        sync: false
      - key: DEEPSEEK_API_KEY  # Critical for AI functionality
        sync: false
      - key: OPENAI_API_KEY
        sync: false
      - key: PINECONE_API_KEY
        sync: false
      - key: ASSEMBLY_AI_API_KEY
        sync: false
      - key: NEO4J_USERNAME
        sync: false
      - key: NEO4J_PASSWORD
        sync: false
      - key: REDIS_URL
        sync: false
      - key: REDIS_API_ACCOUNT_KEY
        sync: false
      - key: REDIS_API_USER_KEY
        sync: false
      - key: HUGGINGFACE_TOKEN
        sync: false
      # ML Model Cache Paths
      - key: TRANSFORMERS_CACHE
        value: /tmp/huggingface/transformers
      - key: HF_HOME
        value: /tmp/huggingface
      - key: TORCH_HOME
        value: /tmp/huggingface/torch
      - key: WHISPER_CACHE
        value: /tmp/huggingface/whisper

databases:  # Optional: Add if you need Redis
  - name: redis
    plan: starter